{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zualexander/mai-aiapp-computer-vision/blob/main/mai_computer_vision_experiment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zm2jaIvte4ON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ca19fc-995a-4f88-c695-96117f983764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PKtRMoeikP40"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (BatchNormalization, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, SeparableConv2D)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import (SGD, RMSprop)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Model\n",
        "import tarfile\n",
        "import os\n",
        "import splitfolders\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsiipT29r--r"
      },
      "source": [
        "#variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xfXdlUGssA0Z"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "img_size = 256\n",
        "train_data_path = '/tmp/dataset/output/train/'\n",
        "val_data_path = '/tmp/dataset/output/val/'\n",
        "input_img = Input(shape=(img_size, img_size, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfWKuQCkBqYO"
      },
      "source": [
        "#Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pPt87ZTnBosU"
      },
      "outputs": [],
      "source": [
        "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "def plot_accuracy_and_loss(history):\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_un2k4KjkaJh"
      },
      "source": [
        "# Download Dataset\n",
        "from [howto](https://towardsdatascience.com/an-informative-colab-guide-to-load-image-datasets-from-github-kaggle-and-local-machine-75cae89ffa1e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVYbndVtkZc6",
        "outputId": "4d41479f-7b56-429e-9d6f-11d653ac802a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-30 10:45:33--  http://aisdatasets.informatik.uni-freiburg.de/freiburg_groceries_dataset/freiburg_groceries_dataset.tar.gz\n",
            "Resolving aisdatasets.informatik.uni-freiburg.de (aisdatasets.informatik.uni-freiburg.de)... 132.230.105.132\n",
            "Connecting to aisdatasets.informatik.uni-freiburg.de (aisdatasets.informatik.uni-freiburg.de)|132.230.105.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 541562880 (516M) [application/x-gzip]\n",
            "Saving to: ‘/tmp/dataset.tar.gz’\n",
            "\n",
            "/tmp/dataset.tar.gz 100%[===================>] 516.47M  30.9MB/s    in 19s     \n",
            "\n",
            "2022-05-30 10:45:53 (27.0 MB/s) - ‘/tmp/dataset.tar.gz’ saved [541562880/541562880]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"\"http://aisdatasets.informatik.uni-freiburg.de/freiburg_groceries_dataset/freiburg_groceries_dataset.tar.gz\"\" \\\n",
        "    -O \"/tmp/dataset.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iF36oM1iHjPi"
      },
      "outputs": [],
      "source": [
        "!mkdir /tmp/dataset \n",
        "!tar xf /tmp/dataset.tar.gz --directory=/tmp/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByAWhvyHKFa2"
      },
      "source": [
        "# Datasplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_XP6AjoOPg4",
        "outputId": "828adc19-e36b-4438-910c-50ab0dd2c399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4947 files [00:01, 3207.25 files/s]\n"
          ]
        }
      ],
      "source": [
        "splitfolders.ratio(\"/tmp/dataset/images\", output=\"/tmp/dataset/output\",\n",
        "    seed=1337, ratio=(.75, .25), group_prefix=None, move=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr1ce8agNuZF",
        "outputId": "ce8a87ee-fa3d-4ebf-c9ca-402aa56e4021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mBEANS\u001b[0m/   \u001b[01;34mCHIPS\u001b[0m/      \u001b[01;34mFISH\u001b[0m/   \u001b[01;34mJUICE\u001b[0m/  \u001b[01;34mPASTA\u001b[0m/   \u001b[01;34mSUGAR\u001b[0m/         \u001b[01;34mWATER\u001b[0m/\n",
            "\u001b[01;34mCAKE\u001b[0m/    \u001b[01;34mCHOCOLATE\u001b[0m/  \u001b[01;34mFLOUR\u001b[0m/  \u001b[01;34mMILK\u001b[0m/   \u001b[01;34mRICE\u001b[0m/    \u001b[01;34mTEA\u001b[0m/\n",
            "\u001b[01;34mCANDY\u001b[0m/   \u001b[01;34mCOFFEE\u001b[0m/     \u001b[01;34mHONEY\u001b[0m/  \u001b[01;34mNUTS\u001b[0m/   \u001b[01;34mSODA\u001b[0m/    \u001b[01;34mTOMATO_SAUCE\u001b[0m/\n",
            "\u001b[01;34mCEREAL\u001b[0m/  \u001b[01;34mCORN\u001b[0m/       \u001b[01;34mJAM\u001b[0m/    \u001b[01;34mOIL\u001b[0m/    \u001b[01;34mSPICES\u001b[0m/  \u001b[01;34mVINEGAR\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls /tmp/dataset/output/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKdJGGwVPQL0",
        "outputId": "15794fc9-6e13-4abd-ebcf-8dda4f07235b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3699 files belonging to 25 classes.\n",
            "Found 1248 files belonging to 25 classes.\n"
          ]
        }
      ],
      "source": [
        "train = keras.utils.image_dataset_from_directory(\n",
        "    directory=train_data_path,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    crop_to_aspect_ratio=True,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_size, img_size))\n",
        "\n",
        "validation = keras.utils.image_dataset_from_directory(\n",
        "    directory=val_data_path,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    crop_to_aspect_ratio=True,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_size, img_size))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbA0bsB8SkXX",
        "outputId": "a941b428-1e1e-465c-82b8-0dcda71d7eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "print(len(train.class_names))\n",
        "classes=train.class_names\n",
        "print(len(classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fRpuWQ6rs75"
      },
      "source": [
        "## data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RHfLFKiVrvVk"
      },
      "outputs": [],
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(                      \n",
        "    rotation_range=90,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    zoom_range=0.2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = keras.preprocessing.image.ImageDataGenerator()"
      ],
      "metadata": {
        "id": "Wel6KXdlCYqV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cFK5bwBr45S",
        "outputId": "1e38d098-6c21-4c8b-b420-8240f3511e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3699 images belonging to 25 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_data_path,\n",
        "                                                    target_size=(img_size, img_size),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RRWwWU4r4-w",
        "outputId": "5786b885-6602-4f03-b8dc-864b3d1f3f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1248 images belonging to 25 classes.\n"
          ]
        }
      ],
      "source": [
        "val_generator = val_datagen.flow_from_directory(val_data_path,\n",
        "                                                    target_size=(img_size, img_size),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM8z2f_VS5D-"
      },
      "source": [
        "#ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "_38nmjPVUqpL"
      },
      "outputs": [],
      "source": [
        "resnet_model = keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=input_img,\n",
        "    input_shape=(img_size, img_size, 3),\n",
        "    pooling=None,\n",
        "    classes=len(classes)\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jNeSxwMg9BO"
      },
      "outputs": [],
      "source": [
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(resnet_model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "yr-AGU4eNki1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Otdsf6h-l2",
        "outputId": "77a43f06-98e5-4504-ec45-37c6e94d8c08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23587712"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "resnet_model.count_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inception Model"
      ],
      "metadata": {
        "id": "tNclV54_PPgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)\n",
        "nClasses = len(classes)\n",
        "print (nClasses)"
      ],
      "metadata": {
        "id": "k_T8icLqPPJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57628660-c9e0-41d5-b747-94a201113a33"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BEANS', 'CAKE', 'CANDY', 'CEREAL', 'CHIPS', 'CHOCOLATE', 'COFFEE', 'CORN', 'FISH', 'FLOUR', 'HONEY', 'JAM', 'JUICE', 'MILK', 'NUTS', 'OIL', 'PASTA', 'RICE', 'SODA', 'SPICES', 'SUGAR', 'TEA', 'TOMATO_SAUCE', 'VINEGAR', 'WATER']\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First inception layer:"
      ],
      "metadata": {
        "id": "-jwKw_2Bbtde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ind = 0\n",
        "for layer in resnet_model.layers[:-1]:\n",
        "  if layer.name == 'conv3_block4_out':\n",
        "    break\n",
        "  ind += 1\n",
        "\n",
        "x = resnet_model.layers[ind].output\n",
        "print (x)\n",
        "\n",
        "layer_1 = Conv2D(10, (1,1), padding='valid', activation='relu')(x)#(input_img)\n",
        "layer_1 = Conv2D(10, (3,3), padding='same', activation='relu')(layer_1)\n",
        "\n",
        "layer_2 = Conv2D(10, (1,1), padding='same', activation='relu')(x)\n",
        "layer_2 = Conv2D(10, (5,5), padding='same', activation='relu')(layer_2)\n",
        "\n",
        "layer_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
        "layer_3 = Conv2D(10, (1,1), padding='same', activation='relu')(layer_3)\n",
        "\n",
        "mid_1 = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)"
      ],
      "metadata": {
        "id": "N7tpUj2eU5Os",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc254cb-6ae4-47fe-d716-c5159b2a0fa5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 512), dtype=tf.float32, name=None), name='conv3_block4_out/Relu:0', description=\"created by layer 'conv3_block4_out'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add dense layers:"
      ],
      "metadata": {
        "id": "ODcxtqDHb_8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flat_1 = Flatten()(mid_1)\n",
        "\n",
        "dense_1 = Dense(512, activation='relu')(flat_1)\n",
        "dense_2 = Dense(32, activation='relu')(dense_1)\n",
        "#dense_3 = Dense(75, activation='relu')(dense_2)\n",
        "output = Dense(nClasses, activation='softmax')(dense_2)"
      ],
      "metadata": {
        "id": "mnQfBRx9bwKT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inception = Model(inputs=input_img, outputs=output)"
      ],
      "metadata": {
        "id": "fwWWnlUJbrmt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model_inception, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "aXvNhrSpcz50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4OrGaEsrhRQp"
      },
      "outputs": [],
      "source": [
        "#model = keras.models.Sequential()\n",
        "\n",
        "#for layer in model_inception.layers:\n",
        "#  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.add(model_inception)\n",
        "#model = Model(model_inception)"
      ],
      "metadata": {
        "id": "KAxU_WVgqME3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "krbuWcHZS4JW"
      },
      "outputs": [],
      "source": [
        "#model.add(keras.layers.Flatten())\n",
        "#model.add(keras.layers.Dense(512, activation='relu'))\n",
        "#model.add(keras.layers.Dense(len(classes), activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VuviVyqVUMr"
      },
      "outputs": [],
      "source": [
        "model_inception.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze conv2 and before"
      ],
      "metadata": {
        "id": "sqofXQdRo4-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_inception.layers[:-1]:\n",
        "  if(layer.name.startswith('conv3')):\n",
        "    break;\n",
        "  layer.trainable = False\n"
      ],
      "metadata": {
        "id": "mrpo09j7o4Kl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6UZCmDZiD4L",
        "outputId": "238ef036-98d9-4ee5-d7d6-fcfb1ee1ceb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10753294"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "model.count_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "L0zAmLceEhtK"
      },
      "outputs": [],
      "source": [
        "#compile model\n",
        "model_inception.compile(\n",
        "  optimizer=keras.optimizers.Adam(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26hgCYK1HBwT"
      },
      "outputs": [],
      "source": [
        "#keras.utils.plot_model(model,show_shapes=True)\n",
        "#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbc17pA-ZO7H",
        "outputId": "d8714300-10fc-4442-f5a6-536ac3c02d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "116/116 [==============================] - 76s 622ms/step - loss: 3.4585 - acc: 0.0665 - val_loss: 3.3614 - val_acc: 0.0617\n",
            "Epoch 2/50\n",
            "116/116 [==============================] - 71s 614ms/step - loss: 3.1401 - acc: 0.0935 - val_loss: 3.9550 - val_acc: 0.0865\n",
            "Epoch 3/50\n",
            "116/116 [==============================] - 71s 612ms/step - loss: 3.0827 - acc: 0.1068 - val_loss: 3.1051 - val_acc: 0.0986\n",
            "Epoch 4/50\n",
            "116/116 [==============================] - 72s 617ms/step - loss: 2.9895 - acc: 0.1263 - val_loss: 4.5707 - val_acc: 0.0962\n",
            "Epoch 5/50\n",
            "116/116 [==============================] - 70s 604ms/step - loss: 2.9392 - acc: 0.1400 - val_loss: 3.1227 - val_acc: 0.1370\n",
            "Epoch 6/50\n",
            "116/116 [==============================] - 70s 607ms/step - loss: 2.8974 - acc: 0.1406 - val_loss: 2.8349 - val_acc: 0.1675\n",
            "Epoch 7/50\n",
            " 57/116 [=============>................] - ETA: 32s - loss: 2.8450 - acc: 0.1584"
          ]
        }
      ],
      "source": [
        "hist = model_inception.fit(train_generator, validation_data=val_generator, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICR2wOFOCGU6"
      },
      "source": [
        "#Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKpXKy-xCKdB"
      },
      "source": [
        "##trainigs history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps0qAc7Qfw0U"
      },
      "outputs": [],
      "source": [
        "print (\"test accuracy \", hist.history['acc'][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bIn2m-_gjsI"
      },
      "source": [
        "#validation history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObgsLehPf73x"
      },
      "outputs": [],
      "source": [
        "print (\"validation accuracy \", hist.history['val_acc'][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7ONXeI8gp8w"
      },
      "source": [
        "#accuracy and loss plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbiShHjjFsgx"
      },
      "outputs": [],
      "source": [
        "print(hist.history.keys())\n",
        "plot_accuracy_and_loss(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFSgMxQ7iVEC"
      },
      "source": [
        "#Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbYhtBspiWP5"
      },
      "outputs": [],
      "source": [
        "Y_pred = model.predict_generator(val_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "con_mat = confusion_matrix(val_generator.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(con_mat)\n",
        "print('Classification Report')\n",
        "print(classification_report(val_generator.classes, y_pred, target_names=classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s8tfCy4klcB"
      },
      "outputs": [],
      "source": [
        "## plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdNBK1H3leL7"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style='darkgrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSzocfQ6kmw3"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat, annot=True,cmap=plt.cm.Dark2)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cstg1F3Ukni7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mai-computer-vision-experiment-2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}